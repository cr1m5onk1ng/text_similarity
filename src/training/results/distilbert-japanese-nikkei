 ------- Running training for model: distilbert-japanese-nikkei -------- 

Params: batch size: 16; number of epochs: 4; frozen weights: True; pretrained embeddings: False
Model params: hidden size: 768; lr: 2e-05; merge strategy: None
validation > epoch: 1; loss: 0.9271643508157245; accuracy: 0.671915196202761; 
training > epoch: 1; loss: 1.281949295829424; accuracy: 0.5557230973646873; 
validation > epoch: 2; loss: 0.860702875473423; accuracy: 0.6938023116779594; 
training > epoch: 2; loss: 0.9621956358978208; accuracy: 0.6590266147977577; 
validation > epoch: 3; loss: 0.8486213241434019; accuracy: 0.6964948911192435; 
training > epoch: 3; loss: 0.8778213947946671; accuracy: 0.6859296135417393; 
validation > epoch: 4; loss: 0.8422572398615288; accuracy: 0.6996743541432661; 
training > epoch: 4; loss: 0.8304134765417647; accuracy: 0.7006289541320679; 


