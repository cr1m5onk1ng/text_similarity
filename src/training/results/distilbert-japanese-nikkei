 ------- Running training for model: distilbert-japanese-nikkei -------- 

Params: batch size: 16; number of epochs: 4; frozen weights: False; pretrained embeddings: False
Model params: hidden size: 768; lr: 2e-05; merge strategy: None
validation > epoch: 1; loss: 0.8892762268201618; accuracy: 0.6842344831334468; 
training > epoch: 1; loss: 1.1943194844968803; accuracy: 0.584565001860768; 
validation > epoch: 2; loss: 0.8077137457681499; accuracy: 0.7100596941918185; 
training > epoch: 2; loss: 0.8277422090140747; accuracy: 0.7058845335287139; 
validation > epoch: 3; loss: 0.7935203641610947; accuracy: 0.7161015797673829; 
training > epoch: 3; loss: 0.7338417434416866; accuracy: 0.7358694293257041; 
validation > epoch: 4; loss: 0.795972504111264; accuracy: 0.7172202797202797; 
training > epoch: 4; loss: 0.6805284171898807; accuracy: 0.7536753802944665; 


